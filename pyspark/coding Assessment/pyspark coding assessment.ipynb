{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74cc0ca-3e48-4dc1-9d7b-68c11db2ff65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: ('RDD Contents:', [('Java', 20000), ('Python', 100000), ('Scala', 3000)])"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()\n",
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "result = rdd.collect()\n",
    "(\"RDD Contents:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94b2bd92-54a1-49cd-ad94-4c7b3915468d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- emp_id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- superior_emp_id: long (nullable = true)\n |-- year_joined: string (nullable = true)\n |-- emp_dept_id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+------+--------+---------------+-----------+-----------+------+------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+--------+---------------+-----------+-----------+------+------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|\n|     2|    Rose|              1|       2010|         20|     M|  4000|\n|     3|Williams|              1|       2010|         10|     M|  1000|\n|     4|   Jones|              2|       2005|         10|     F|  2000|\n|     5|   Brown|              2|       2010|         40|      |    -1|\n|     6|   Brown|              2|       2010|         50|      |    -1|\n+------+--------+---------------+-----------+-----------+------+------+\n\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|  Finance|     10|\n|Marketing|     20|\n|    Sales|     30|\n|       IT|     40|\n+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000),(2, \"Rose\",1 , \"2010\", \"20\",\"M\", 4000),(3,\"Williams\",1,\"2010\",\"10\",\"M\",1000),(4, \"Jones\",2 ,\"2005\",\"10\",\"F\",2000),(5,\"Brown\",2,\"2010\",\"40\",\"\",-1),(6, \"Brown\", 2, \"2010\",\"50\",\"\",-1)]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show()\n",
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "833c82d1-0a0f-47de-aaeb-da07cc076c30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#INNER JOIN\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650d51a3-cc01-488c-86f9-83983cfedcf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#OUTER JOIN \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb18a13b-bf70-4912-aa47-8b72d3f7a04b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#LEFT JOIN\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd772fe-3cb8-4da5-a816-51904e690cb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#RIGHT JOIN\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8008904f-13c4-48d7-8b72-1ba9d147a768",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+--------+---------------+-----------+-----------+------+------+\n|     1|   Smith|             -1|       2018|         10|     M|  3000|\n|     3|Williams|              1|       2010|         10|     M|  1000|\n|     4|   Jones|              2|       2005|         10|     F|  2000|\n|     2|    Rose|              1|       2010|         20|     M|  4000|\n|     5|   Brown|              2|       2010|         40|      |    -1|\n+------+--------+---------------+-----------+-----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#LEFT SEMI JOIN \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85eb8664-e608-41b5-9af0-9c038defbc98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+-----+---------------+-----------+-----------+------+------+\n|     6|Brown|              2|       2010|         50|      |    -1|\n+------+-----+---------------+-----------+-----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#LEFT ANTI JOIN \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a58c4ca-0e73-43a3-bf46-46da13c82d3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulated DataFrame:\n+-------+-----------+---+----------+\n|   Name| Department|Age|New_Salary|\n+-------+-----------+---+----------+\n| srujan|  Marketing| 28|   66000.0|\n|sharath|Engineering| 30|   82500.0|\n|sumedha|    Finance| 32|   77000.0|\n| yogesh|  Marketing| 33|   79200.0|\n|  tejas|Engineering| 35|   88000.0|\n+-------+-----------+---+----------+\n\n\nAverage Salary: 78540.0\n\nGrouped Data:\n+-----------+---------------+\n| Department|avg(New_Salary)|\n+-----------+---------------+\n|Engineering|        85250.0|\n|    Finance|        77000.0|\n|  Marketing|        72600.0|\n+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataFrame Operations Example\") \\\n",
    "    .getOrCreate()\n",
    "# Create DataFrame\n",
    "data = [(\"sharath\", \"Engineering\", 30, 75000),\n",
    "        (\"srujan\", \"Marketing\", 28, 60000),\n",
    "        (\"tejas\", \"Engineering\", 35, 80000),\n",
    "        (\"sumedha\", \"Finance\", 32, 70000),\n",
    "        (\"yogesh\", \"Marketing\", 33, 72000)]\n",
    "columns = [\"Name\", \"Department\", \"Age\", \"Salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "# Manipulating data: Adding a new column\n",
    "df = df.withColumn(\"New_Salary\", col(\"Salary\") * 1.1)\n",
    "# Dropping a column\n",
    "df = df.drop(\"Salary\")\n",
    "# Sorting by Age\n",
    "df = df.orderBy(\"Age\")\n",
    "# Aggregations\n",
    "avg_salary = df.select(avg(\"New_Salary\")).first()[0]\n",
    "# GroupBy\n",
    "grouped_data = df.groupBy(\"Department\").agg(avg(\"New_Salary\"))\n",
    "# Displaying results\n",
    "print(\"Manipulated DataFrame:\")\n",
    "df.show()\n",
    "print(\"\\nAverage Salary:\", avg_salary)\n",
    "print(\"\\nGrouped Data:\")\n",
    "grouped_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "771cbf1c-eae0-4cde-8d23-c064a054de7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+------+\n|   Name|       DOB|Gender|salary|\n+-------+----------+------+------+\n|sharath|2002-04-01|     M|  3000|\n| srujan|2001-05-19|     M|  4000|\n|  tejas|2002-09-05|     M|  4000|\n|sumedha|2001-12-01|     M|  4000|\n| yogesh|2000-02-17|     M|  1200|\n+-------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#SELECTING RENAMING FILTERING DATA'S IN PANDAS\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pyspark - example join').getOrCreate()\n",
    "data = [(('sharath'), '2002-04-01', 'M', 3000),\n",
    "        (('srujan'), '2001-05-19', 'M', 4000),\n",
    "        (('tejas'), '2002-09-05', 'M', 4000),\n",
    "        (('sumedha'), '2001-12-01', 'M', 4000),\n",
    "        (('yogesh'), '2000-02-17', 'M', 1200)]\n",
    "columns = [\"Name\", \"DOB\", \"Gender\", \"salary\"]\n",
    "# Create the spark dataframe\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32dc246c-6c0e-4bbc-8a32-c0f2e4eb74e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+------+\n|   Name|DateOfBirth|Gender|salary|\n+-------+-----------+------+------+\n|sharath| 2002-04-01|     M|  3000|\n| srujan| 2001-05-19|     M|  4000|\n|  tejas| 2002-09-05|     M|  4000|\n|sumedha| 2001-12-01|     M|  4000|\n| yogesh| 2000-02-17|     M|  1200|\n+-------+-----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DOB\",\"DateOfBirth\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "178b7422-37a4-4981-b9d8-4a3f4edcd3f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+------+\n|   Name|       DOB|Sex|Amount|\n+-------+----------+---+------+\n|sharath|2002-04-01|  M|  3000|\n| srujan|2001-05-19|  M|  4000|\n|  tejas|2002-09-05|  M|  4000|\n|sumedha|2001-12-01|  M|  4000|\n| yogesh|2000-02-17|  M|  1200|\n+-------+----------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "#RENAME MULTIPLE COLUMNS\n",
    "df.withColumnRenamed(\"Gender\",\"Sex\").withColumnRenamed(\"salary\",\"Amount\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c11d5e61-cf18-4059-83ec-1932a7532ffa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+------+\n|   name|       DOB|Gender|salary|\n+-------+----------+------+------+\n|sharath|2002-04-01|     M|  3000|\n| srujan|2001-05-19|     M|  4000|\n|  tejas|2002-09-05|     M|  4000|\n|sumedha|2001-12-01|     M|  4000|\n| yogesh|2000-02-17|     M|  1200|\n+-------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#using expr\n",
    "data = df.selectExpr(\"Name as name\",\"DOB\",\"Gender\",\"salary\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd78da1-8702-4a7b-8249-1da5919af8df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+------+\n|   Name|       DOB|Gender|Amount|\n+-------+----------+------+------+\n|sharath|2002-04-01|     M|  3000|\n| srujan|2001-05-19|     M|  4000|\n|  tejas|2002-09-05|     M|  4000|\n|sumedha|2001-12-01|     M|  4000|\n| yogesh|2000-02-17|     M|  1200|\n+-------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#USING SELECT METHOD\n",
    "from pyspark.sql.functions import col\n",
    " \n",
    "# Select the 'salary' as 'Amount' using aliasing\n",
    "# Select remaining with their original name\n",
    "data = df.select(col(\"Name\"),col(\"DOB\"),\n",
    "                 col(\"Gender\"),\n",
    "                 col(\"salary\").alias('Amount'))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bd16a7-d79a-4b1b-82ab-4ca66c86aae1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+-----------+\n|Emp Name|Date of Birth| Gender-m/f|Paid salary|\n+--------+-------------+-----------+-----------+\n| sharath|   2002-04-01|          M|       3000|\n|  srujan|   2001-05-19|          M|       4000|\n|   tejas|   2002-09-05|          M|       4000|\n| sumedha|   2001-12-01|          M|       4000|\n|  yogesh|   2000-02-17|          M|       1200|\n+--------+-------------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#USING DF\n",
    "Data_list = [\"Emp Name\",\"Date of Birth\",\n",
    "             \" Gender-m/f\",\"Paid salary\"]\n",
    " \n",
    "new_df = df.toDF(*Data_list)\n",
    "new_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark coding assessment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
